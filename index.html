<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=K3QJPdMAAAAJ&hl=en" target="_blank">Bichen Wu,</span>
                <span class="author-block">
                  <a href="https://chingyaoc.github.io" target="_blank">Ching-Yao Chuang,</span>
                  <a href="https://xiaoyan.horizonian.com/" target="_blank">Xiaoyan Wang,</span>
                  <a href="https://www.linkedin.com/in/yichen-jia-1545b564/" target="_blank">Yichen Jia,</span> <br>
                  <a href="https://scholar.google.com/citations?user=gMAME_YAAAAJ&hl=en" target="_blank">Kapil Krishnakumar,</span>
                  <a href="http://xiaotong.me/" target="_blank">Tong Xiao,</span>
                  <a href="https://jeff-liangf.github.io/" target="_blank">Feng Liang,</span>
                  <a href="https://lichengunc.github.io/" target="_blank">Licheng Yu,</span>
                  <a href="https://sites.google.com/site/vajdap" target="_blank">Peter Vajda</a>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">GenAI, Meta</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    <!-- Supplementary -->
                    <span class="link-block">
                      <a href="./supp/index.html" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-link"></i>
                      </span>
                      <span>Supplementary</span>
                      </a>
                    </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/fairy.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
In this paper, we introduce Fairy, a minimalist yet robust adaptation of image-editing diffusion models, enhancing them for video editing applications. Our approach centers on the concept of anchor-based cross-frame attention, a mechanism that implicitly propagates diffusion features across frames, ensuring superior temporal coherence and high-fidelity synthesis. Fairy not only addresses limitations of previous models, including memory and processing speed. It also improves temporal consistency through a unique data augmentation strategy. This strategy renders the model equivariant to affine transformations in both source and target images. Remarkably efficient, Fairy generates 120-frame 512x384 videos (4-second duration at 30 FPS) in just 14 seconds, outpacing prior works by at least 44x. A comprehensive user study, involving 1000 generated samples, confirms that our approach delivers superior quality, decisively outperforming established methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Paper poster -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
            <table width="800" border="0">
              <tbody>
                <tr>
                  <td colspan="3">
                    <p>
                      <a style="color:red">Fairy re-examines the tracking-and-propagation paradigm under the context of diffusion model features.</a>
                      In particular, we bridge cross-frame attention with correspondence estimation, showing that it temporally tracks and propagates intermediate features inside a diffusion model. The cross-frame attention map can be interpreted as a similarity metric assessing the correspondence between tokens throughout various frames, where features from one semantic region will assign higher attention to similar semantic regions in other frames, as shown in the following figure (Fig. 3). Consequently, the current feature representations are refined and propagated through a weighted sum of similar regions across frames via attention, effectively minimizing feature disparity between frames, which translates to improved temporal consistency.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <figure>
              <img src="supp/assets/fig_tracking_example.png" alt="" width="1000" />
              <figcaption>Figure 3: Visualization of Attention Score. The left image shows the query point $p$ within the current frame, and the right image is the target frame. Cross-frame attention performs accurate temporal correspondence estimation without any finetuning. </figcaption>
            </figure>
            <p>
              <a style="color:red">The analysis gives rise to our anchor-based model, the central component of Fairy.</a> To ensure temporal consistency, we sample K anchor frames from which we extract diffusion features, and the extracted features define a set global features to be propagated to successive frames. When generating each new frame, we replace the self-attention layer with cross-frame attention with respect to the cached features of anchor frames. With cross-frame attention, the tokens in each frame take the features in anchor frames that exhibit analogous semantic content, thereby enhancing consistency.
            </p>

            <figure>
              <img src="supp/assets/fig_method.png" alt="" width="600" />
              <figcaption>
                Figure 4: Illustration of Attention Blocks (a) Given a set of anchor frames, we extract and cache the attention feature
                <span class="math inline">\(K_{anc}\)</span> and
                <span class="math inline">\(V_{anc}\)</span>.
                (b) Given an input frame, we perform cross-frame attention with respect to the cached features of anchor frames.
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End paper poster -->



<!-- Begin Qualitative Results section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-">
          <h2 class="title is-3">Qualitative Results</h2>
          <div class="content has-text-justified">

              <p style= width="1000">
                In this section, we showcase videos generated by Fairy. We process all frames from the source video, without temporal downsampling or frame interpolation. We resize the output video's longer side to 512, and keep the aspect ratio the same. <br>
                <a style="color:red">Please look at <a href="./supp/index.html">Supplimentary videos</a> for more results!</a>
                <br>
              </p>

              <!-- ========Character/Object Swap============ -->
              <h3 id="character_swap" align="left"><a name="character_swap" id="character_swap"></a> 1. Character/Object Swap</h3>
              <div class="container-1">
                <div class="video-container-character swiper-container">
                  <div class="swiper-wrapper">
                    <div class="swiper-slide">
                      <table width="1100" align="center">
                        <tr>
                          <th><a href="./supp/assets/qualitative/charswap/not_a_human_6.mp4"> <a
                                href="./supp/assets/qualitative/charswap/not_a_human_6.mp4"> <video id="master11" width="250"
                                  src="./supp/assets/qualitative/charswap/not_a_human_6.mp4" autoplay loop controls muted /> </a> </a>
                          </th>
                          <th><a href="./supp/assets/qualitative/charswap/not_a_human_9.mp4"> <a
                                href="./supp/assets/qualitative/charswap/not_a_human_9.mp4"> <video id="master12" width="250"
                                  src="./supp/assets/qualitative/charswap/not_a_human_9.mp4" autoplay loop controls muted /> </a> </a>
                          </th>
                          <th><a href="./supp/assets/qualitative/charswap/cat_walking_3.mp4"> <a
                                href="./supp/assets/qualitative/charswap/cat_walking_3.mp4"> <video id="master13" width="250"
                                  src="./supp/assets/qualitative/charswap/cat_walking_3.mp4" autoplay loop controls muted /> </a> </a>
                          </th>
                          <th><a href="./supp/assets/qualitative/charswap/dog_smiling.mp4"> <a
                                href="./supp/assets/qualitative/charswap/dog_smiling.mp4"> <video id="master14" width="250"
                                  src="./supp/assets/qualitative/charswap/dog_smiling.mp4" autoplay loop controls muted /> </a> </a>
                          </th>
                        </tr>
                        <tr>
                          <th style="font-family: Chalkduster" width="250"> "Turn into a metal knight sculpture" </th>
                          <th style="font-family: Chalkduster" width="250"> "Turn into a yeti" </th>
                          <th style="font-family: Chalkduster" width="250"> "Turn into a wood sculpture" </th>
                          <th style="font-family: Chalkduster" width="250"> "Turn into a marble Roman sculpture" </th>
                        </tr>
                        <tr>
                          <th><a href="./supp/assets/qualitative/charswap/not_a_human_6_prompt_turn_into_a_metal_knight_sculpture.mp4">
                              <a href="./supp/assets/qualitative/charswap/not_a_human_6_prompt_turn_into_a_metal_knight_sculpture.mp4">
                                <video data-master-id="master11" width="250"
                                  src="./supp/assets/qualitative/charswap/not_a_human_6_prompt_turn_into_a_metal_knight_sculpture.mp4"
                                  autoplay loop controls muted /> </a> </a></th>
                          <th><a href="./supp/assets/qualitative/charswap/not_a_human_9_prompt_turn_into_a_yeti.mp4"> <a
                                href="./supp/assets/qualitative/charswap/not_a_human_9_prompt_turn_into_a_yeti.mp4"> <video
                                  data-master-id="master12" width="250"
                                  src="./supp/assets/qualitative/charswap/not_a_human_9_prompt_turn_into_a_yeti.mp4" autoplay loop
                                  controls muted /> </a> </a></th>
                          <th><a href="./supp/assets/qualitative/charswap/cat_walking_3.mp4_prompt_turn_into_a_wood_sculpture.mp4"> <a
                                href="./supp/assets/qualitative/charswap/cat_walking_3.mp4_prompt_turn_into_a_wood_sculpture.mp4">
                                <video data-master-id="master13" width="250"
                                  src="./supp/assets/qualitative/charswap/cat_walking_3.mp4_prompt_turn_into_a_wood_sculpture.mp4"
                                  autoplay loop controls muted /> </a> </a></th>
                          <th><a
                              href="./supp/assets/qualitative/charswap/dog_smiling.mp4_prompt_turn_into_a_marble_roman_sculpture.mp4">
                              <a
                                href="./supp/assets/qualitative/charswap/dog_smiling.mp4_prompt_turn_into_a_marble_roman_sculpture.mp4">
                                <video data-master-id="master14" width="250"
                                  src="./supp/assets/qualitative/charswap/dog_smiling.mp4_prompt_turn_into_a_marble_roman_sculpture.mp4"
                                  autoplay loop controls muted /> </a> </a></th>
                        </tr>
                      </table>

                </div>
              </div>


              <!-- ========Stylization============ -->
              <h3 id="Stylization" align="left"><a name="stylization" id="stylization"></a> 2. Stylization</h3>

              <div class="container-2">
                <div class="video-container-stylizaton swiper-container">
                  <div class="swiper-wrapper">
                    <div class="swiper-slide">
                      <table width="800" align="center">
                        <tr>
                          <th><a href="./supp/assets/qualitative/stylization/dog_shaking.mp4"> <a
                                href="./supp/assets/qualitative/stylization/dog_shaking.mp4"> <video id="master21" width="400"
                                  src="./supp/assets/qualitative/stylization/dog_shaking.mp4" autoplay loop controls muted /> </a> </a>
                          </th>
                          <th><a href="./supp/assets/qualitative/stylization/cat_walking.mp4"> <a
                                href="./supp/assets/qualitative/stylization/cat_walking.mp4"> <video id="master22" width="400"
                                  src="./supp/assets/qualitative/stylization/cat_walking.mp4" autoplay loop controls muted /> </a> </a>
                          </th>
                        </tr>
                        <tr>
                          <th style="font-family: Chalkduster" width="400"> "In Van Gogh style" </th>
                          <th style="font-family: Chalkduster" width="400"> "In low poly art style" </th>

                        </tr>
                        <tr>
                          <th><a href="./supp/assets/qualitative/stylization/dog_shaking_prompt_in_van_gogh_style.mp4"> <a
                                href="./supp/assets/qualitative/stylization/dog_shaking_prompt_in_van_gogh_style.mp4"> <video
                                  data-master-id="master21" width="400"
                                  src="./supp/assets/qualitative/stylization/dog_shaking_prompt_in_van_gogh_style.mp4" autoplay loop
                                  controls muted /> </a> </a></th>
                          <th><a href="./supp/assets/qualitative/stylization/cat_walking_prompt_in_low_poly_art_style.mp4"> <a
                                href="./supp/assets/qualitative/stylization/cat_walking_prompt_in_low_poly_art_style.mp4"> <video
                                  data-master-id="master22" width="400"
                                  src="./supp/assets/qualitative/stylization/cat_walking_prompt_in_low_poly_art_style.mp4" autoplay
                                  loop controls muted /> </a> </a></th>

                        </tr>
                      </table>

                  </div>
                  <div class="swiper-button-prev">
                    <i class="uil uil-angle-left-b swiper-icon"></i>
                  </div>

                  <div class="swiper-button-next">
                    <i class="uil uil-angle-right-b swiper-icon"></i>
                  </div>

                </div>
              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
    <!------------------ END SECTION ------------------>


  <!------------------ BEGIN SECTION: Comparison ------------------>
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">User study</h2>
          <div class="content has-text-justified">


              <p style= width="1000">

                In this paper, we conduct a large-scale user study on an evaluation set consists of 1000 video-instruction samples. To our best knowledge, this is the largest evaluation in the video- to-video generation literature so far. <br>
                We compare extensively with existing methods: TokenFlow, Renderer, and Gen-1. <br>
                <a style="color:red">Please look at <a href="./supp/index.html">Supplimentary videos</a> for qualitative comparsion!</a>
              </p>
            <figure>
              <img src="supp/assets/fig_exp_ab.png" alt="" width="1000" />
              <figcaption>Figure 7. A/B Comparison with Baselines. Fairy significantly surpassed baseline models, demonstrating its effectivity. </figcaption>
            </figure>
                </div>
              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
    <!------------------ END SECTION ------------------>




<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Coming soon</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
